{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udce1 Welcome to pyhfss","text":"<p><code>pyhfss</code> is a Python package for automating HFSS simulations using PyAEDT. It supports structured workflows, parameter sweeps, and JSON/CSV result aggregation. Simulation interfaces for <code>EigenmodeAnalysis</code> and <code>QuantumEPR</code> are included.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>\ud83d\udce6 Installation \u2013 Install the package</li> <li>\ud83e\uddea Simulation Guide \u2014 Use <code>QuantumEPR</code>, <code>EigenmodeAnalysis</code>, and more</li> <li>\u2699\ufe0f Automation Guide \u2014 Define and execute parameterized simulation workflows</li> </ul> <p>Example workflows available</p> <p>Check the <code>examples/</code> folder in the repo for working templates.</p>"},{"location":"install/","title":"\ud83d\udce6 Installation Guide","text":""},{"location":"install/#prerequisites","title":"Prerequisites","text":"<p>The two non trivial requirements for this package are:</p> <ul> <li>pyaedt - used for interacting with HFSS</li> <li>pykit - used for automation and safe data manipulation (see Automation)</li> <li>Python 3.11 or higher</li> </ul>"},{"location":"install/#steps","title":"Steps","text":"<pre><code>git clone https://github.com/RosenblumLab/pyhfss.git\npip install -e &lt;PATH_TO_PYHFSS&gt;\n</code></pre>"},{"location":"api/design_variable_builder/","title":"DesignVariableBuilder","text":"<p>Set project-level design variables in an HFSS simulation model.</p> <p>This builder applies design parameters to the active project before analysis, enabling full parametric sweeps.</p> <p>               Bases: <code>BaseBuilder</code></p> <p>Builder for setting design variables in an HFSS model.</p> <p>This builder sets project-level design parameters before simulation. It\u2019s useful for parametrizing a model and enabling sweeps.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['design_variable_builder']</code> <p>Identifier for this builder type.</p> <code>design_name</code> <code>str</code> <p>Name of the HFSS design to activate.</p>"},{"location":"api/design_variable_builder/#pyhfss.workflow.builder.design_variable_builder.DesignVariableBuilder.build","title":"build","text":"<pre><code>build(hfss: Hfss, parameters: dict = None) -&gt; dict\n</code></pre> <p>Apply design variables to the HFSS project.</p> <p>Parameters:</p> Name Type Description Default <code>hfss</code> <code>Hfss</code> <p>Active HFSS session.</p> required <code>parameters</code> <code>dict</code> <p>Dictionary of design variables and their values.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary, confirming the values set in the design.</p> Source code in <code>src/pyhfss/workflow/builder/design_variable_builder.py</code> <pre><code>def build(self, hfss: Hfss,\n          parameters: dict = None) -&gt; dict:\n\n    \"\"\"\n    Apply design variables to the HFSS project.\n\n    Args:\n        hfss: Active HFSS session.\n        parameters: Dictionary of design variables and their values.\n\n    Returns:\n        dict: The same dictionary, confirming the values set in the design.\n    \"\"\"\n\n    if parameters is None:\n        return {}\n\n    hfss.set_active_design(self.design_name)\n    set_variables(hfss, parameters)\n    return parameters\n</code></pre>"},{"location":"api/eigenmode_analysis/","title":"EigenmodeAnalysis","text":"<p>Run an Eigenmode simulation in HFSS and extract modal frequencies and Q-factors.</p> <p>This class wraps setup configuration, simulation execution, and result parsing in a single, declarative interface. It's typically used in workflow configurations to automate eigenmode extraction.</p> <p>               Bases: <code>BaseAnalysis</code></p> <p>Runs an Eigenmode simulation using an existing HFSS setup.</p> <p>This simulation extracts resonant frequencies and quality factors from the eigenmodes of a 3D electromagnetic structure in HFSS.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal[EIGENMODE]</code> <p>Type of simulation. Always set to 'eigenmode'.</p> <code>setup_name</code> <code>str</code> <p>Name of the HFSS setup to run.</p> <code>design_name</code> <code>str</code> <p>Name of the HFSS design to use.</p> <code>cores</code> <code>int</code> <p>Number of CPU cores to allocate (default is 4).</p> <code>gpus</code> <code>int</code> <p>Number of GPUs to allocate (default is 0).</p> <code>setup_parameters</code> <code>dict</code> <p>Optional dictionary of parameters to override the setup configuration.</p>"},{"location":"api/eigenmode_analysis/#pyhfss.simulation.eigenmode.model.EigenmodeAnalysis.analyze","title":"analyze","text":"<pre><code>analyze(hfss: Hfss) -&gt; EigenmodeResults\n</code></pre> <p>Execute the Eigenmode simulation and extract results.</p> <p>Parameters:</p> Name Type Description Default <code>hfss</code> <code>Hfss</code> <p>An active HFSS project instance.</p> required <p>Returns:</p> Name Type Description <code>EigenmodeResults</code> <code>EigenmodeResults</code> <p>Object containing frequencies and Q-factors of each eigenmode.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>hfss</code> is not a valid Hfss instance.</p> Source code in <code>src/pyhfss/simulation/eigenmode/model.py</code> <pre><code>def analyze(self, hfss: Hfss) -&gt; EigenmodeResults:\n    \"\"\"\n    Execute the Eigenmode simulation and extract results.\n\n    Args:\n        hfss: An active HFSS project instance.\n\n    Returns:\n        EigenmodeResults: Object containing frequencies and Q-factors of each eigenmode.\n\n    Raises:\n        ValueError: If `hfss` is not a valid Hfss instance.\n    \"\"\"\n    if not isinstance(hfss, Hfss):\n        raise ValueError('hfss given must be a Hfss instance')\n\n    setup = set_design_and_get_setup(hfss, self.design_name, self.setup_name)\n\n    # check for application of setup parameters\n    update_setup_parameters(setup, self.setup_parameters)\n\n    # validate solution type\n    validate_solution_type(setup, setup_type='HfssEigen')\n\n    # Analyze\n    setup.analyze(cores=self.cores, gpus=self.gpus)\n\n    # Save and exit\n    hfss.save_project()\n\n    return get_eigenmode_results(setup=setup)\n</code></pre>"},{"location":"api/eigenmode_analysis/#pyhfss.simulation.eigenmode.model.EigenmodeAnalysis.check_requirement","title":"check_requirement","text":"<pre><code>check_requirement()\n</code></pre> <p>Check simulation requirements. Currently, a placeholder.</p> Source code in <code>src/pyhfss/simulation/eigenmode/model.py</code> <pre><code>def check_requirement(self):\n    \"\"\"Check simulation requirements. Currently, a placeholder.\"\"\"\n    pass\n</code></pre>"},{"location":"api/eigenmode_analysis/#pyhfss.simulation.eigenmode.model.EigenmodeAnalysis.report","title":"report","text":"<pre><code>report()\n</code></pre> <p>Generate a simulation report. Currently, a placeholder.</p> Source code in <code>src/pyhfss/simulation/eigenmode/model.py</code> <pre><code>def report(self):\n    \"\"\"Generate a simulation report. Currently, a placeholder.\"\"\"\n    pass\n</code></pre>"},{"location":"api/eigenmode_results/","title":"EigenmodeResults","text":"<p>A result object containing all modal data extracted from an Eigenmode simulation.</p> <p>Each mode includes its frequency, quality factor, and optional label. The result can be flattened into tabular form or relabeled for use in quantum workflows.</p> <p>               Bases: <code>BaseSimulationOutput</code></p> <p>Result container for an Eigenmode simulation.</p> <p>Stores computed modes, each with its frequency and quality factor. Provides utilities to transform, flatten, and relabel the results.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal[EIGENMODE_RESULT]</code> <p>Simulation result type identifier (always 'eigenmode_result').</p> <code>results</code> <code>dict[int, SingleModeResult]</code> <p>Mapping of mode index to a SingleModeResult instance.</p> <code>frequencies_unit</code> <code>str</code> <p>The unit in which frequencies are expressed (default: 'GHz').</p>"},{"location":"api/eigenmode_results/#pyhfss.simulation.eigenmode.results.EigenmodeResults.change_frequencies_unit","title":"change_frequencies_unit","text":"<pre><code>change_frequencies_unit(unit: str)\n</code></pre> <p>Change the unit of all stored frequencies.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>str</code> <p>New frequency unit (e.g., 'MHz', 'GHz', etc.)</p> required Source code in <code>src/pyhfss/simulation/eigenmode/results.py</code> <pre><code>def change_frequencies_unit(self, unit: str):\n    \"\"\"\n    Change the unit of all stored frequencies.\n\n    Args:\n        unit: New frequency unit (e.g., 'MHz', 'GHz', etc.)\n    \"\"\"\n    self.frequencies_unit = unit\n    for v in self.results.values():\n        v.change_frequency_unit(self.frequencies_unit)\n</code></pre>"},{"location":"api/eigenmode_results/#pyhfss.simulation.eigenmode.results.EigenmodeResults.flatten","title":"flatten","text":"<pre><code>flatten() -&gt; FlatDictType\n</code></pre> <p>Flatten the result into a dictionary for tabular or CSV output.</p> <p>Returns:</p> Type Description <code>FlatDictType</code> <p>A flat dictionary with labeled keys and scalar values.</p> Source code in <code>src/pyhfss/simulation/eigenmode/results.py</code> <pre><code>def flatten(self) -&gt; FlatDictType:\n    \"\"\"\n    Flatten the result into a dictionary for tabular or CSV output.\n\n    Returns:\n        A flat dictionary with labeled keys and scalar values.\n    \"\"\"\n    result = {}\n    for mode_number in self.results.keys():\n        current = self.results[mode_number].flatten()\n        result.update(current)\n    return result\n</code></pre>"},{"location":"api/eigenmode_results/#pyhfss.simulation.eigenmode.results.EigenmodeResults.generate_a_labeled_version","title":"generate_a_labeled_version","text":"<pre><code>generate_a_labeled_version(\n    mode_to_labels: dict[int, str],\n) -&gt; EigenmodeResults\n</code></pre> <p>Create a new result object with mode labels assigned.</p> <p>Parameters:</p> Name Type Description Default <code>mode_to_labels</code> <code>dict[int, str]</code> <p>Mapping of mode index to label string.</p> required <p>Returns:</p> Name Type Description <code>EigenmodeResults</code> <code>EigenmodeResults</code> <p>A labeled version of the results.</p> Source code in <code>src/pyhfss/simulation/eigenmode/results.py</code> <pre><code>def generate_a_labeled_version(self, mode_to_labels: dict[int, str]) -&gt; EigenmodeResults:\n    \"\"\"\n    Create a new result object with mode labels assigned.\n\n    Args:\n        mode_to_labels: Mapping of mode index to label string.\n\n    Returns:\n        EigenmodeResults: A labeled version of the results.\n    \"\"\"\n    new_results = {}\n    modes = sorted(mode_to_labels.keys())\n    for i, mode in enumerate(modes):\n        label = mode_to_labels[mode]\n        item = self.results[mode].model_copy()\n        item.label = label\n        item.mode_number = i\n        new_results[i] = item\n    return EigenmodeResults(results=new_results, frequencies_unit=self.frequencies_unit)\n</code></pre>"},{"location":"api/eigenmode_results/#pyhfss.simulation.eigenmode.results.EigenmodeResults.generate_simple_form","title":"generate_simple_form","text":"<pre><code>generate_simple_form() -&gt; dict[int, dict[str, float]]\n</code></pre> <p>Convert the result set to a simplified dict format.</p> <p>Returns:</p> Type Description <code>dict[int, dict[str, float]]</code> <p>A dictionary mapping each mode to its frequency and quality factor.</p> Source code in <code>src/pyhfss/simulation/eigenmode/results.py</code> <pre><code>def generate_simple_form(self) -&gt; dict[int, dict[str, float]]:\n    \"\"\"\n    Convert the result set to a simplified dict format.\n\n    Returns:\n        A dictionary mapping each mode to its frequency and quality factor.\n    \"\"\"\n    return {\n        elem.mode_number: {'frequency': elem.frequency.value,\n                           'quality_factor': elem.quality_factor}\n        for elem in self.results.values()\n    }\n</code></pre>"},{"location":"api/eigenmode_results/#related","title":"Related","text":"<ul> <li><code>EigenmodeAnalysis</code></li> </ul>"},{"location":"api/execute_workflow/","title":"execute_workflow","text":"<p>The main automation function that utilized a WorkflowConfig to run a sequence of phases based on its parameters. </p> <p>Run a complete, cached HFSS experiment workflow.</p> <p>The engine performs four deterministic phases:</p> <ol> <li>Prepare \u2013 create an isolated results folder and, if requested,    copy the template <code>.aedt</code> project into it.</li> <li>Build \u2013 apply the current sweep parameters to the HFSS design    through the configured builder object.</li> <li>Simulate \u2013 execute one or more analyses for every parameter set    and store their JSON results.</li> <li>Aggregate \u2013 flatten and merge selected results into CSV files    for downstream analysis.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>WorkflowConfig</code> <p>Parsed workflow definition. See the full field reference in <code>api/workflow_config.md</code>.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the configuration is incomplete.</p> <code>RuntimeError</code> <p>If an HFSS session cannot be opened or a simulation fails unexpectedly.</p> Example <pre><code>from pathlib import Path\nfrom pyhfss import (\n    WorkflowConfig, PyaedtFileParameters,\n    EigenmodeAnalysis, DesignVariableBuilder, execute_workflow\n)\nfrom pykit.sweeper import DictSweep\n\ncfg = WorkflowConfig(\n    pyaedt_file_parameters=PyaedtFileParameters(\n        file_path=Path(\"resources/simple_design.aedt\"),\n        non_graphical=True\n    ),\n    builder=DesignVariableBuilder(design_name=\"my_design\"),\n    builder_sweep=[DictSweep(parameters={\"chip_base_width\": [\"3 mm\", \"4 mm\"]})],\n    simulations={\n        \"classical\": EigenmodeAnalysis(setup_name=\"Setup1\",\n                                       design_name=\"my_design\")\n    },\n    aggregation_dict={\"classical_agg\": [\"classical\"]}\n)\n\nexecute_workflow(cfg)\n# \u2192 results/aggregations/classical_agg.csv is produced\n</code></pre> Source code in <code>src/pyhfss/workflow/workflow.py</code> <pre><code>def execute_workflow(config: WorkflowConfig) -&gt; None:\n    \"\"\"\n    Run a complete, cached HFSS experiment workflow.\n\n    The engine performs four deterministic phases:\n\n    1. **Prepare** \u2013 create an isolated results folder and, if requested,\n       copy the template ``.aedt`` project into it.\n    2. **Build** \u2013 apply the current sweep parameters to the HFSS design\n       through the configured builder object.\n    3. **Simulate** \u2013 execute one or more analyses for every parameter set\n       and store their JSON results.\n    4. **Aggregate** \u2013 flatten and merge selected results into CSV files\n       for downstream analysis.\n\n    Args:\n        config (WorkflowConfig):\n            Parsed workflow definition.\n            See the full field reference in\n            [`api/workflow_config.md`](../api/workflow_config.md).\n\n    Returns:\n        None\n\n    Raises:\n        ValueError: If the configuration is incomplete.\n        RuntimeError: If an HFSS session cannot be opened or a simulation\n            fails unexpectedly.\n\n    Example:\n        ```python\n        from pathlib import Path\n        from pyhfss import (\n            WorkflowConfig, PyaedtFileParameters,\n            EigenmodeAnalysis, DesignVariableBuilder, execute_workflow\n        )\n        from pykit.sweeper import DictSweep\n\n        cfg = WorkflowConfig(\n            pyaedt_file_parameters=PyaedtFileParameters(\n                file_path=Path(\"resources/simple_design.aedt\"),\n                non_graphical=True\n            ),\n            builder=DesignVariableBuilder(design_name=\"my_design\"),\n            builder_sweep=[DictSweep(parameters={\"chip_base_width\": [\"3 mm\", \"4 mm\"]})],\n            simulations={\n                \"classical\": EigenmodeAnalysis(setup_name=\"Setup1\",\n                                               design_name=\"my_design\")\n            },\n            aggregation_dict={\"classical_agg\": [\"classical\"]}\n        )\n\n        execute_workflow(cfg)\n        # \u2192 results/aggregations/classical_agg.csv is produced\n        ```\n    \"\"\"\n    project = Project(root=config.root_folder)\n    iteration_proj = project.sub(\"iterations\")\n\n    chain_sweep = ChainSweep(sweepers=config.builder_sweep)\n\n    for params in chain_sweep.generate():\n\n        # 1. PREPARE (copy template .aedt if policy allows)\n        run_params = _prepare_folder_phase(\n            cfg=config.prepare_folder,\n            pyaedt=config.pyaedt_file_parameters,\n            params=params,\n            project=iteration_proj,\n        )\n\n        # 2. BUILD (apply parameter sweep values)\n        _build_phase(config.builder, run_params, params, iteration_proj)\n\n        # 3. SIMULATIONS\n        _simulations_phase(\n            config.simulations,\n            params,\n            run_params.model_copy(),\n            iteration_proj,\n        )\n\n    # 4. AGGREGATION\n    aggregation_proj = project.sub(\"aggregations\")\n    for name, identifiers in config.aggregation_dict.items():\n        aggregator = Aggregator(identifiers=identifiers)\n        _aggregation_phase(name, aggregator, aggregation_proj, iteration_proj)\n</code></pre>"},{"location":"api/function_builder/","title":"FunctionBuilder","text":"<p>Call a user-defined Python function to build or modify the HFSS model.</p> <p>This builder is highly flexible and useful for dynamic setups.</p> <p>               Bases: <code>BaseBuilder</code></p> <p>Builder that delegates logic to a user-defined Python function.</p> <p>This builder is highly flexible and useful when programmatic or external control over the build process is needed.</p> <p>The user-supplied function must have the following signature:</p> <pre><code>def my_builder_function(hfss: Hfss, **kwargs) -&gt; dict:\n    ...\n</code></pre> <ul> <li><code>hfss</code>: The active HFSS session object.</li> <li><code>**kwargs</code>: Arbitrary keyword arguments, typically containing build parameters.</li> <li>The function must return a dictionary with any results or output parameters.</li> </ul> Example <pre><code>def builder_function(hfss, name_value_dict):\n    for name, value in name_value_dict.items():\n        hfss[name] = value\n    return {\"status\": \"ok\"}\n</code></pre> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['function_builder']</code> <p>Identifier for this builder type.</p> <code>function</code> <code>Callable[[Hfss, ...], dict]</code> <p>Callable object (excluded from serialization).</p> <code>args</code> <code>dict</code> <p>Static arguments passed to the function at runtime.</p>"},{"location":"api/function_builder/#pyhfss.workflow.builder.function_builder.FunctionBuilder.build","title":"build","text":"<pre><code>build(hfss: Hfss, parameters: dict | None = None) -&gt; dict\n</code></pre> <p>Call the user-defined function with merged arguments.</p> <p>Parameters:</p> Name Type Description Default <code>hfss</code> <code>Hfss</code> <p>Active HFSS session.</p> required <code>parameters</code> <code>dict | None</code> <p>Optional runtime parameters. These are merged with <code>args</code> and passed as keyword arguments to the function.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Output of the user-defined function.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Any exception raised by the user-supplied function will propagate up.</p> Source code in <code>src/pyhfss/workflow/builder/function_builder.py</code> <pre><code>def build(self, hfss: Hfss,\n          parameters: dict | None = None) -&gt; dict:\n    \"\"\"\n    Call the user-defined function with merged arguments.\n\n    Args:\n        hfss: Active HFSS session.\n        parameters: Optional runtime parameters. These are merged with `args` and passed as keyword arguments to the function.\n\n    Returns:\n        dict: Output of the user-defined function.\n\n    Raises:\n        Exception: Any exception raised by the user-supplied function will propagate up.\n    \"\"\"\n\n    parameters = parameters or {}\n    combined_args = merge_dicts(self.args, parameters)\n\n    return self.function(hfss, **combined_args)\n</code></pre>"},{"location":"api/module_builder/","title":"ModuleBuilder","text":"<p>Import and run a Python module as a builder.</p> <p>Use this to integrate reusable external scripts that define the model logic. Helpful for sharing build logic across multiple projects.</p> <p>               Bases: <code>BaseBuilder</code></p> <p>Builder that dynamically imports a module and calls a specified function.</p> <p>This allows you to build HFSS models using external, version-controlled scripts. Especially useful for reusable templates and team collaboration.</p> <p>The imported function must have the following signature:</p> <pre><code>def build(hfss: Hfss, **kwargs) -&gt; dict:\n    ...\n</code></pre> <ul> <li><code>hfss</code>: The active HFSS session object.</li> <li><code>**kwargs</code>: Arbitrary keyword arguments, typically containing build parameters.</li> <li>The function must return a dictionary with any results or output parameters.</li> </ul> Example <pre><code>def build(hfss, name_to_value):\n    for name, value in name_to_value.items():\n        hfss[name] = value\n    return {\"status\": \"ok\"}\n</code></pre> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['module_builder']</code> <p>Identifier for this builder type.</p> <code>module</code> <code>str</code> <p>Python module path (e.g., 'mypkg.submodule').</p> <code>function</code> <code>str</code> <p>Name of the function in the module to call (default: 'build').</p> <code>args</code> <code>dict</code> <p>Static arguments passed to the function.</p>"},{"location":"api/module_builder/#pyhfss.workflow.builder.module_builder.ModuleBuilder.build","title":"build","text":"<pre><code>build(hfss: Hfss, parameters: dict | None = None) -&gt; dict\n</code></pre> <p>Import the specified module, call its build function with merged arguments.</p> <p>Parameters:</p> Name Type Description Default <code>hfss</code> <code>Hfss</code> <p>Active HFSS session.</p> required <code>parameters</code> <code>dict | None</code> <p>Runtime arguments to merge with predefined <code>args</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Output of the module's function call.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If the module or function cannot be imported.</p> <code>Exception</code> <p>Any exception raised by the user-supplied function will propagate up.</p> Source code in <code>src/pyhfss/workflow/builder/module_builder.py</code> <pre><code>def build(self,\n          hfss: Hfss,\n          parameters: dict | None = None) -&gt; dict:\n    \"\"\"\n    Import the specified module, call its build function with merged arguments.\n\n    Args:\n        hfss: Active HFSS session.\n        parameters: Runtime arguments to merge with predefined `args`.\n\n    Returns:\n        dict: Output of the module's function call.\n\n    Raises:\n        ImportError: If the module or function cannot be imported.\n        Exception: Any exception raised by the user-supplied function will propagate up.\n    \"\"\"\n    # Merge any runtime parameters with the builder's predefined arguments\n    parameters = parameters or {}\n    combined_args = merge_dicts(self.args, parameters)\n\n    # Dynamically import the specified module\n    imported_module = importlib.import_module(self.module)\n\n    # Retrieve the function (default is \"build\") from the imported module\n    try:\n        build_func = getattr(imported_module, self.function)\n    except AttributeError:\n        raise AttributeError(\n            f\"Function '{self.function}' not found in module '{self.module}'.\"\n        )\n\n    # Call the function, passing in the HFSS object plus merged arguments\n    result = build_func(hfss, **combined_args)\n    return result\n</code></pre>"},{"location":"api/prepare_folder_config/","title":"PrepareFolderConfig","text":"<p>Configuration options for the folder preparation phase of a simulation run.</p> <p>This model defines whether to copy the source AEDT file and what to name it in each simulation folder.</p> <p>               Bases: <code>BaseModel</code></p> <p>Configuration for the prepare phase of the workflow.</p> <p>This determines how the working directory is initialized before the simulation is executed.</p> <p>Attributes:</p> Name Type Description <code>copy_enabled</code> <code>bool</code> <p>If True, the source AEDT file will be copied; otherwise, it runs in-place.</p> <code>dest_name</code> <code>str</code> <p>Filename to use for the copied AEDT file inside each simulation folder.</p>"},{"location":"api/pyaedt_file_parameters/","title":"PyaedtFileParameters","text":"<p>Launch and manage an AEDT (HFSS) session based on file and license settings.</p> <p>This model is used during every stage of the workflow where HFSS access is required. It provides a context-managed interface to automatically open and clean up HFSS projects.</p> <p>               Bases: <code>BaseModel</code></p> <p>Configuration for launching and managing an AEDT (HFSS) session.</p> <p>This object controls how the <code>.aedt</code> file is opened, including settings related to license availability, GUI behavior, and session cleanup.</p> <p>It is used during the prepare, build, and simulate phases of the simulation workflow.</p> <p>Attributes:</p> Name Type Description <code>file_path</code> <code>PATH_TYPE</code> <p>Path to the source <code>.aedt</code> project file.</p> <code>design_name</code> <code>str</code> <p>Name of the design to open (defaults to \"temp\").</p> <code>version</code> <code>Literal['2024.2']</code> <p>AEDT version to use (e.g., \"2024.2\").</p> <code>non_graphical</code> <code>bool</code> <p>Whether to run AEDT in non-graphical mode.</p> <code>new_desktop</code> <code>bool</code> <p>If True, starts a new AEDT desktop instance.</p> <code>close_on_exit</code> <code>bool</code> <p>Whether to automatically close AEDT after exiting the context.</p>"},{"location":"api/pyaedt_file_parameters/#pyhfss.workflow.session_handler.config.PyaedtFileParameters.open_pyaedt_file","title":"open_pyaedt_file","text":"<pre><code>open_pyaedt_file() -&gt; Generator[Hfss, None, None]\n</code></pre> <p>Open an HFSS session using the specified file and settings.</p> <p>Returns a context-managed <code>Hfss</code> instance that is ready to use.</p> <p>Yields:</p> Type Description <code>Hfss</code> <p>An active and validated <code>Hfss</code> object.</p> <p>Raises:</p> Type Description <code>LicenseUnavailableError</code> <p>If no valid design is loaded (e.g., license issue).</p> Source code in <code>src/pyhfss/workflow/session_handler/config.py</code> <pre><code>@contextmanager\ndef open_pyaedt_file(self) -&gt; Generator[Hfss, None, None]:\n    \"\"\"\n    Open an HFSS session using the specified file and settings.\n\n    Returns a context-managed `Hfss` instance that is ready to use.\n\n    Yields:\n        An active and validated `Hfss` object.\n\n    Raises:\n        LicenseUnavailableError: If no valid design is loaded (e.g., license issue).\n    \"\"\"\n    with Hfss(\n            non_graphical=self.non_graphical,\n            version=self.version,\n            new_desktop=self.new_desktop,\n            close_on_exit=self.close_on_exit,\n            design=self.design_name,\n            project=str(self.file_path.resolve()),\n            remove_lock=True\n    ) as hfss:\n        # Immediately check if HFSS initialized to a valid state\n        if not hfss.valid_design:\n            # Close the session and signal unavailability\n            raise LicenseUnavailableError(\n                \"HFSS session created but no valid design \u2014 likely license or startup issue.\"\n            )\n\n        try:\n            yield hfss\n        finally:\n            # Optional cleanup\n            if 'temp' in hfss.design_list:\n                print(\"Cleaning up: Deleting temporary HFSS design.\")\n                hfss.delete_design(\"temp\")\n</code></pre>"},{"location":"api/quantum_epr/","title":"QuantumEPR","text":"<p>Run a quantum simulation using Energy Participation Ratio (EPR) analysis.</p> <p>This class orchestrates a distributed HFSS simulation, extracts participation data for defined junctions, and computes the quantum <code>\u03c7</code> (chi) matrix via numerical diagonalization.</p> <p>               Bases: <code>BaseAnalysis</code></p> <p>Runs an EPR-based quantum simulation using Eigenmode results and junction data.</p> <p>This analysis calculates energy participation ratios (EPR), anharmonicities, and the chi matrix for quantum circuit modes. It integrates multiple simulation stages into a high-level quantum post-processing workflow.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal[QUANTUM_EPR]</code> <p>Simulation type identifier (always set to 'quantum_epr').</p> <code>design_name</code> <code>str</code> <p>Name of the HFSS design to use.</p> <code>setup_name</code> <code>str</code> <p>Name of the HFSS setup that has Eigenmode results.</p> <code>modes_to_labels</code> <code>MODES_TO_LABELS_TYPE</code> <p>Either a parser or mapping from mode index to label.</p> <code>junctions_infos</code> <code>JUNCTION_INFO_TYPE</code> <p>Configuration objects describing the Josephson junctions.</p>"},{"location":"api/quantum_epr/#pyhfss.simulation.quantum_epr.model.QuantumEPR.analyze","title":"analyze","text":"<pre><code>analyze(hfss: Hfss) -&gt; QuantumResults\n</code></pre> <p>Run the full EPR simulation and return results.</p> <p>This includes distributed EM simulation, participation ratio extraction, and EPR matrix diagonalization.</p> <p>Parameters:</p> Name Type Description Default <code>hfss</code> <code>Hfss</code> <p>An active HFSS project instance.</p> required <p>Returns:</p> Name Type Description <code>QuantumResults</code> <code>QuantumResults</code> <p>Final output containing EPR matrix, participation data, and labeled eigenmode results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>hfss</code> is not a valid Hfss instance.</p> Source code in <code>src/pyhfss/simulation/quantum_epr/model.py</code> <pre><code>def analyze(self, hfss: Hfss) -&gt; QuantumResults:\n    \"\"\"\n    Run the full EPR simulation and return results.\n\n    This includes distributed EM simulation, participation ratio extraction,\n    and EPR matrix diagonalization.\n\n    Args:\n        hfss: An active HFSS project instance.\n\n    Returns:\n        QuantumResults: Final output containing EPR matrix, participation data, and labeled eigenmode results.\n\n    Raises:\n        ValueError: If `hfss` is not a valid Hfss instance.\n    \"\"\"\n\n    if not isinstance(hfss, Hfss):\n        raise ValueError('hfss given must be a Hfss instance')\n\n    validate_and_set_design(hfss, self.design_name)\n\n    # getting setup and getting\n    setup = hfss.get_setup(self.setup_name)\n\n    # getting eigenmode solution in simple form, meaning it is\n    # of type dict[int, dict[str, float]\n    # where the keys are the mode number and the values are frequency dict and quality factor dict\n    eigenmode_result = get_eigenmode_results(setup)\n\n    # convert modes to labels to dict of int to str\n    # in case of ModesAndLabels object call for parse\n    modes_to_labels = self.modes_to_labels\n\n    if isinstance(modes_to_labels, ModesAndLabels):\n        modes_to_labels = modes_to_labels.parse(eigenmode_result.generate_simple_form())\n\n    epr, distributed = self._analyze(hfss, modes_to_labels)\n\n    return QuantumResults(\n        epr=epr,\n        distributed=distributed,\n        eigenmode_result=eigenmode_result.generate_a_labeled_version(modes_to_labels)\n    )\n</code></pre>"},{"location":"api/quantum_results/","title":"QuantumResult","text":"<p>The final output of a quantum EPR simulation. This object contains the diagonalized chi matrix, participation data from the distributed analysis, and labeled modal data from EigenmodeResults.</p> <p>               Bases: <code>BaseSimulationOutput</code></p> <p>Final result object for quantum EPR analysis.</p> <p>This result aggregates: - A numerically diagonalized chi matrix (<code>epr</code>) - A raw distributed simulation result (<code>distributed</code>) - A labeled set of eigenmode data (<code>eigenmode_result</code>)</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal[QUANTUM_EPR_RESULT]</code> <p>Simulation result type identifier (always 'quantum_epr_result').</p> <code>epr</code> <code>EprDiagResultType</code> <p>Result of chi matrix diagonalization and EPR computation.</p> <code>distributed</code> <code>ParticipationDatasetType</code> <p>Raw participation dataset across modes and junctions.</p> <code>eigenmode_result</code> <code>EigenmodeResults</code> <p>Labeled EigenmodeResults used in the computation.</p>"},{"location":"api/quantum_results/#pyhfss.simulation.quantum_epr.results.QuantumResults.flatten","title":"flatten","text":"<pre><code>flatten() -&gt; FlatDictType\n</code></pre> <p>Flatten the result into a dictionary containing chi matrix values, frequencies, and quality factors.</p> <p>Returns:</p> Type Description <code>FlatDictType</code> <p>A flat dictionary with scalar entries suitable for tabular export.</p> Source code in <code>src/pyhfss/simulation/quantum_epr/results.py</code> <pre><code>def flatten(self) -&gt; FlatDictType:\n    \"\"\"\n    Flatten the result into a dictionary containing chi matrix values,\n    frequencies, and quality factors.\n\n    Returns:\n        A flat dictionary with scalar entries suitable for tabular export.\n    \"\"\"\n\n    flat_dict = {}\n\n    chi_flat_dict = dict(self._flatten_chi())\n    frequencies_flat_dict = dict(self._flatten_frequencies_and_q_factors())\n\n    flat_dict.update(chi_flat_dict)\n    flat_dict.update(frequencies_flat_dict)\n    return flat_dict\n</code></pre>"},{"location":"api/quantum_results/#related","title":"Related","text":"<ul> <li><code>QuantumEPR</code></li> </ul>"},{"location":"api/workflow_config/","title":"WorkflowConfig","text":"<p>Top-level configuration model for a simulation workflow.</p> <p>Defines the root directory, simulations to run, builder logic, and aggregation strategies. Can be saved/loaded from YAML.</p> <pre><code>def my_function(x, y):\n    result = x + y\n    return result\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Top-level configuration model for a simulation workflow.</p> <p>This class defines how simulations are structured, executed, and aggregated. It is typically serialized/deserialized to YAML for reproducible workflows.</p> <p>Attributes:</p> Name Type Description <code>root_folder</code> <code>PathType</code> <p>Root directory where simulation results will be saved. default: 'results'</p> <code>pyaedt_file_parameters</code> <code>PyaedtFileParameters</code> <p>Configuration for how the <code>.aedt</code> file is opened and managed during simulation. See <code>PyaedtFileParameters</code> for full control over versioning, licensing, and graphical behavior.</p> <code>simulations</code> <code>dict[str, SUPPORTED_ANALYSIS]</code> <p>Mapping of simulation names to simulation configuration objects. Each value must be one of the supported analysis types:</p> <ul> <li><code>EigenmodeAnalysis</code></li> <li><code>QuantumEPR</code></li> </ul> <p>These are selected using a <code>type</code> field discriminator, as defined in <code>SUPPORTED_ANALYSIS</code>.</p> <code>builder</code> <code>SUPPORTED_BUILDERS | None</code> <p>Optional object used to modify the HFSS model before simulation.</p> <p>Supported builder types:</p> <ul> <li><code>DesignVariableBuilder</code></li> <li><code>FunctionBuilder</code></li> <li><code>ModuleBuilder</code></li> </ul> <p>The builder must define a <code>type</code> field used for runtime selection.</p> <code>builder_sweep</code> <code>list[DictSweep]</code> <p>Optional parameter sweep applied to the builder phase.</p> <p>Accepts any normalized sweep configuration such as:</p> <ul> <li><code>DictSweep</code> (basic dictionary-based parameter combinations)</li> <li><code>ChainSweep</code> (product of multiple sweeps)</li> <li><code>EmptySweep</code> (default/no sweep)</li> </ul> <p>These are automatically normalized using <code>NormalizedSweep</code>.</p> <code>aggregation_dict</code> <code>dict[str, list[str]]</code> <p>Optional aggregation rules for result post-processing.</p> <p>Each key maps to a list of strings which should be all simulation identifiers. This dict is converted to <code>Aggregator</code> which than go for each key and aggregate its list of identifiers (e.g., flattening, validation, merging by UID).</p> <p>See <code>pykit.aggregator.Aggregator</code> for behavior.</p>"},{"location":"api/workflow_config/#pyhfss.workflow.config.WorkflowConfig.load_from_yaml","title":"load_from_yaml  <code>classmethod</code>","text":"<pre><code>load_from_yaml(path: str | Path) -&gt; WorkflowConfig\n</code></pre> <p>Load a workflow configuration from a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Source file path.</p> required <p>Returns:</p> Name Type Description <code>WorkflowConfig</code> <code>WorkflowConfig</code> <p>Parsed configuration object.</p> Source code in <code>src/pyhfss/workflow/config.py</code> <pre><code>@classmethod\ndef load_from_yaml(cls, path: str | Path) -&gt; WorkflowConfig:\n    \"\"\"\n    Load a workflow configuration from a YAML file.\n\n    Args:\n        path: Source file path.\n\n    Returns:\n        WorkflowConfig: Parsed configuration object.\n    \"\"\"\n    return parse_yaml_file_as(cls, path)\n</code></pre>"},{"location":"api/workflow_config/#pyhfss.workflow.config.WorkflowConfig.save_to_yaml","title":"save_to_yaml","text":"<pre><code>save_to_yaml(path: str | Path) -&gt; None\n</code></pre> <p>Save this configuration to a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Target file path.</p> required Source code in <code>src/pyhfss/workflow/config.py</code> <pre><code>def save_to_yaml(self, path: str | Path) -&gt; None:\n    \"\"\"\n    Save this configuration to a YAML file.\n\n    Args:\n        path: Target file path.\n    \"\"\"\n    to_yaml_file(path, self, map_indent=4)\n</code></pre>"},{"location":"guides/automation/","title":"\u2699\ufe0f Automation Workflows","text":"<p>A workflow is a function that enables automated simulation runs. For each parameter set it passes through four phases:</p> Phase What happens Config keys\u00b9 Prepare Create a folder; optionally copy an existing .AEDT. <code>prepare_folder</code> Build Modify the .AEDT for the current parameters. <code>builder</code>, <code>builder_sweep</code> Simulate Run analyses for each sweep point.\u00b2 <code>simulations</code> Aggregate Merge JSON outputs into CSV tables. <code>aggregation_dict</code> <p>\u00b9 Full field docs: WorkflowConfig \u00b2 Identifiers \"build\" and \"prepare\" are reserved \u2013 see details in Simulate.</p> <p>Reruns are incremental: finished steps are skipped automatically.</p>"},{"location":"guides/automation/#quick-start","title":"Quick-start","text":"<p>A minimal Python example using <code>WorkflowConfig</code> and <code>execute_workflow</code>.</p> <p>Python example</p> <pre><code>from pathlib import Path\nfrom pyhfss import (\n    WorkflowConfig, PyaedtFileParameters,\n    EigenmodeAnalysis, DesignVariableBuilder, execute_workflow\n)\nfrom pykit.sweeper import DictSweep\n\nconfig = WorkflowConfig(\n    pyaedt_file_parameters=PyaedtFileParameters(\n        file_path=Path(\"resources/simple_design.aedt\")                  # Read AEDT\n    ),\n    builder=DesignVariableBuilder(design_name=\"my_design\"),             # Modify model\n\n    builder_sweep=[DictSweep(                                           # Parameter combos\n                    parameters={\"chip_base_width\": [\"3 mm\", \"4 mm\"]}\n                    )],                                                 \n    simulations={                                                       # What to run\n        \"classical\": EigenmodeAnalysis(setup_name=\"Setup1\",\n                                       design_name=\"my_design\")\n    },\n    aggregation_dict={\"classical_agg\": [\"build\", \"classical\"]}          # How to merge\n)\n\nexecute_workflow(config)\n</code></pre> <p>What you\u2019ll see</p> <pre><code>results/iterations/&lt;uid&gt;/\n\u251c\u2500 build/parameters.json        # {\"chip_base_width\": \"3 mm\" | \"4 mm\"}\n\u2514\u2500 classical/classical.json     # simulation output\n\nresults/aggregations/classical_agg.csv   # parameters merged with results\n</code></pre> <p>Note</p> <p><code>\"build\"</code> and <code>\"prepare\"</code> are reserved identifiers and therefore cannot be used as keys in <code>simulations</code>. <code>\"build\"</code> holds sweep parameters; <code>\"prepare\"</code> stores the path to the copied AEDT.</p>"},{"location":"guides/automation/#phases","title":"Phases","text":""},{"location":"guides/automation/#prepare-folders-templates","title":"Prepare \u2013 Folders &amp; Templates","text":"<p><code>PrepareFolderConfig</code> decides whether the template .AEDT file is copied and what name it will have. The user doesn't need specify anything, this is a default behavior.</p> <pre><code>results/iterations/&lt;uid&gt;/\n\u2514\u2500 build.aedt\n</code></pre> <p>Copy rules</p> <p><code>copy_enabled = True</code> (default) \u2013 duplicate the template for each sweep.</p>"},{"location":"guides/automation/#build-modify-the-model","title":"Build \u2013 Modify the Model","text":"<p>A builder receives an open HFSS session plus the current parameter dict.</p> Builder type Purpose <code>DesignVariableBuilder</code> Set design variables <code>FunctionBuilder</code> Run a user-supplied Python function <code>ModuleBuilder</code> Import and execute <code>&lt;module&gt;.build()</code> <p>Traceability</p> <p>Each sweep\u2019s parameters are saved to <code>build/parameters.json</code>.</p>"},{"location":"guides/automation/#simulate-run-analyses","title":"Simulate \u2013 Run Analyses","text":"<p><code>simulations</code> is a <code>dict[str, Simulation]</code> (see the Simulations guide for APIs). Keys are identifiers used later for aggregation.</p> <p>Reserved identifiers</p> <p>Do not name a simulation <code>\"build\"</code> or <code>\"prepare\"</code> \u2013 those identifiers are reserved for internal bookkeeping.</p> <p>Simulations dict</p> <pre><code>    simulations = {\n        \"classical\": EigenmodeAnalysis(setup_name=\"Setup1\",\n                                       design_name=\"my_design\"),\n        \"epr\": QuantumEPR(setup_name=\"Setup1\",\n                          design_name=\"my_design\",\n                          modes_to_labels={0: \"q0\"})\n    }\n</code></pre> <p>Outputs are JSON files:</p> <pre><code>results/iterations/&lt;uid&gt;/&lt;identifier&gt;.json\n</code></pre>"},{"location":"guides/automation/#aggregate-collect-results","title":"Aggregate \u2013 Collect Results","text":"<pre><code>aggregation_dict = {\n    \"classical_agg\": [\"classical\"],\n    \"combined\":      [\"classical\", \"epr\"]\n}\n</code></pre> <p>For each entry the engine:</p> <ol> <li>Loads matching result files.</li> <li>Calls <code>.flatten()</code> to turn nested keys into columns (see Simulations guide).</li> <li>Writes a CSV in <code>results/aggregations/</code>.</li> </ol>"},{"location":"guides/best_practices/","title":"\ud83d\ude80 Best Practices for Cluster Jobs","text":"<p><code>pyhfss</code> is designed so that a workflow you test on your laptop will behave the same way on a large compute cluster. Follow the sequence below to keep every run predictable, repeatable, and cluster-ready.</p>"},{"location":"guides/best_practices/#1-pick-the-right-builder","title":"1 \u00b7 Pick the Right Builder","text":"<p>Choose a builder that matches how you want to create or edit the HFSS model:</p> Builder When to Use Docs DesignVariableBuilder You already have an <code>.aedt</code> and only need to tweak project-level variables. <code>DesignVariableBuilder</code> ModuleBuilder You prefer a reusable Python module to generate or modify geometry. <code>ModuleBuilder</code> <p>(See the full list in the API reference under Builders.)</p>"},{"location":"guides/best_practices/#2-define-everything-in-a-config-file","title":"2 \u00b7 Define Everything in a Config File","text":"<p>Create a single YAML/TOML file containing design variables, solver options, and cluster resources. If it might change between runs, put it in the config\u2014not in Python code.</p>"},{"location":"guides/best_practices/#3-test-locally","title":"3 \u00b7 Test Locally","text":"<pre><code>pyhfss run config.yaml\n</code></pre> <p>A local run confirms the builder and settings work before you consume cluster hours.</p>"},{"location":"guides/best_practices/#4-submit-to-the-cluster","title":"4 \u00b7 Submit to the Cluster","text":"<pre><code>pyhfss submit config.yaml my_env --name job_name\n</code></pre> <p><code>submit</code> copies the project, packages the config, and hands off the job to the scheduler.</p> <p>Tip</p> <p>Commit the config file\u2014and the design artefacts\u2014to Git. With code and configuration under version control, every cluster run can be traced, repeated, and trusted.</p>"},{"location":"guides/simulations/","title":"\ud83e\uddea Simulations Guide","text":"<p>This guide outlines the usage, design principles, and interfaces of the simulation classes provided in this package.</p> <p>Currently supported simulation types:</p> <ul> <li>EigenmodeAnalysis</li> <li>QuantumEPR</li> </ul> <p>All simulation classes follow a consistent interface to ensure ease of use, automation, and result handling.</p>"},{"location":"guides/simulations/#design-philosophy","title":"Design Philosophy","text":"<p>Unified Simulation Interface</p> <p>All simulation classes conform to two core constraints:</p> <ol> <li>Implement an <code>.analyze(hfss)</code> method that runs the simulation.</li> <li>Return a JSON-serializable object that supports flattening for aggregation.</li> </ol> <p>This approach enables uniform integration into pipelines, simplifies logging, and supports downstream analysis (e.g., storing results in databases or converting to tables using Pandas).</p> <p>About Flattening</p> <p>The <code>.flatten()</code> method converts the result into a flat dictionary with simple key-value pairs. This is useful for aggregation or tabular data storage but may omit nested information.</p> <p>For full data preservation, use:</p> <pre><code>result.model_dump()        # Full result as a nested dict\nresult.model_dump_json()   # JSON-formatted string\n</code></pre> <p>Use <code>.flatten()</code> primarily for aggregation, and <code>.model_dump()</code> or <code>.model_dump_json()</code> for saving or inspection.</p> CPU Configuration <p>The Eigenmode Analysis class includes a <code>cores</code> attribute.  This can be used to control how many CPU cores are requested or used, particularly useful when submitting jobs to a computing cluster.</p>"},{"location":"guides/simulations/#using-simulation-classes","title":"Using Simulation Classes","text":"<p>Importing and Executing a Simulation</p> <pre><code>from pyhfss.simulation import EigenmodeAnalysis\n\nanalysis = EigenmodeAnalysis(\n    design_name=\"MyDesign\",\n    setup_name=\"Setup1\"\n)\n\nresult = analysis.analyze(hfss)\n\n# Access specific results\nresult.results[1].quality_factor    # Quality factor for mode 1\nresult.results[1].frequency         # Frequency for mode 1\n\n# For saving or aggregation, see .model_dump(), .flatten(), etc.\n</code></pre>"},{"location":"guides/terminal/","title":"\ud83d\udda5\ufe0f Command-Line Usage Guide","text":"<p>The <code>pyhfss</code> command-line interface (CLI) allows you to manage simulation workflows using configuration files \u2014 no Python scripting needed.</p> <p>There are two primary commands:</p> <ul> <li><code>pyhfss run</code>: Run a simulation locally</li> <li><code>pyhfss submit</code>: Submit a simulation job to a compute cluster</li> </ul> <p>Both commands rely on a <code>config.yaml</code> file to define the workflow logic and parameters.</p> <p>Getting command options</p> <p>To explore available options for either command, use:</p> <pre><code>pyhfss run --help\npyhfss submit --help\n</code></pre>"},{"location":"guides/terminal/#local-execution-with-run","title":"Local Execution with <code>run</code>","text":"<p>The <code>run</code> command is a configuration-based tool for executing workflows locally:</p> <pre><code>pyhfss run config.yaml\n</code></pre> <p>It is typically used to:</p> <ul> <li>Test the automation workflow before submitting to a cluster</li> <li>Run quick simulations for development or debugging</li> </ul> <p>Tip</p> <p>Keep different <code>config.yaml</code> files for different simulation setups. This avoids duplicating Python code and makes testing easier.</p> <pre><code>pyhfss run configs/design_3mm.yaml\npyhfss run configs/design_4mm.yaml\n</code></pre>"},{"location":"guides/terminal/#cluster-submission-with-submit","title":"Cluster Submission with <code>submit</code>","text":"<p>The <code>submit</code> command packages and submits a simulation job to a compute cluster (e.g., LSF with <code>bsub</code>):</p> <pre><code>pyhfss submit config.yaml my_env --name job_name\n</code></pre> <p>This creates a new folder and places all required files inside it to run the job remotely.</p>"},{"location":"guides/terminal/#expected-folder-layout","title":"Expected Folder Layout","text":"<pre><code>job_name/\n\u251c\u2500\u2500 config.yaml\n\u251c\u2500\u2500 [copied input files]\n\u251c\u2500\u2500 simulate.sh\n\u2514\u2500\u2500 job_submission.sh\n</code></pre> File Description <code>config.yaml</code> The configuration file defining the simulation workflow <code>[copied input files]</code> Any additional files provided via the <code>--files</code> option <code>simulate.sh</code> Activates <code>my_env</code> (Conda) and runs <code>pyhfss run config.yaml</code> <code>job_submission.sh</code> A submission script to run <code>simulate.sh</code> via <code>bsub</code> on the cluster <p>Usage example</p> <pre><code>pyhfss submit config.yaml my_env --name batch_run --files my_design.aedt --mem 160000 --timeout 06:00\n</code></pre> <p>Note</p> <p><code>my_env</code> must be the name of a Conda environment available on the cluster. The environment is activated inside <code>simulate.sh</code>.</p> <p>Note</p> <p>The number of CPUs requested from the cluster depends on the <code>cores</code> setting in your <code>EigenmodeAnalysis</code> simulation configuration.</p>"},{"location":"guides/terminal/#related-guides","title":"Related Guides","text":"<ul> <li>Automation Workflows \u2013 Understand the simulation pipeline</li> <li>Simulations \u2013 Available simulation types and structure</li> <li>WorkflowConfig \u2013 Full YAML schema reference</li> </ul>"}]}