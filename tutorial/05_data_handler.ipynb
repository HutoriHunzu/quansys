{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf95af0e",
   "metadata": {},
   "source": [
    "# DataHandler Tutorial Example\n",
    "\n",
    "In this notebook, we demonstrate how to use the **DataHandler** module to manage simulation outputs. This example complements our other tutorials and illustrates the following steps:\n",
    "\n",
    "- **Folder and Iteration Setup:** Create the necessary folder hierarchy and start new iterations.\n",
    "- **Data Registration and Saving:** Register simulation output identifiers and add sample data.\n",
    "- **Aggregation and Export:** Aggregate data from multiple iterations and export the results as CSV files.\n",
    "\n",
    "Let's walk through each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a1e1e",
   "metadata": {},
   "source": [
    "## Step 0: Preparation of example data to save\n",
    "The data handler assume some strcuture on the data that is saving. the strcuture is as follows:\n",
    "1. the data object are passed as dict\n",
    "2. the data object itself should has a method called flatten which returns a flat dict\n",
    "3. for the aggregation it is required to pass an adapter. the adapter is an instance that gets as input dict and returns the correct instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d0d9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Import required modules and models\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing_extensions import Literal, Annotated\n",
    "from pydantic import BaseModel, TypeAdapter, Field\n",
    "\n",
    "# Import the DataHandler (adjust the import path as needed)\n",
    "from pysubmit.workflow.data_handler.new_data_handler import DataHandler\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Define Simulation Output Models with flatten() methods\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "class Parameters(BaseModel):\n",
    "    type: Literal['parameters'] = 'parameters'\n",
    "    id: str = 'build_parameters'\n",
    "    parameters: dict = {}\n",
    "\n",
    "    def flatten(self) -> dict:\n",
    "        return self.parameters\n",
    "\n",
    "class Classical(BaseModel):\n",
    "    type: Literal['classical'] = 'classical'\n",
    "    id: str\n",
    "    result: dict = {}\n",
    "\n",
    "    def flatten(self) -> dict:\n",
    "        return self.result\n",
    "\n",
    "class Quantum(BaseModel):\n",
    "    type: Literal['quantum'] = 'quantum'\n",
    "    id: str\n",
    "    result: dict = {}\n",
    "\n",
    "    def flatten(self) -> dict:\n",
    "        return self.result\n",
    "\n",
    "# Define the discriminated union for our simulation outputs.\n",
    "datatype = Annotated[Parameters | Classical | Quantum, Field(discriminator='type')]\n",
    "adapter = TypeAdapter(datatype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb75e42",
   "metadata": {},
   "source": [
    "## Step 1: Setup Folder Structure and Create Iterations\n",
    "\n",
    "We first create the folder hierarchy. Here, we enable the `overwrite` option to start fresh. Then, we create multiple iterations (4 iterations) to simulate different simulation runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0e1a8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 145] The directory is not empty: 'demo_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m handler = DataHandler(root_directory=root_dir)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Create the folder hierarchy with overwrite enabled.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mhandler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFolder hierarchy created (overwrite enabled).\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\pysubmit\\src\\pysubmit\\workflow\\data_handler\\new_data_handler.py:174\u001b[39m, in \u001b[36mDataHandler.create_folders\u001b[39m\u001b[34m(self, overwrite)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03mCreates the main folder hierarchy:\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    - root_directory / results_directory\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m \u001b[33;03m    overwrite (bool): Whether to delete existing folders before creation (default False).\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overwrite \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.root_directory.exists():\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28mself\u001b[39m.root_directory.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28mself\u001b[39m.results_directory = \u001b[38;5;28mself\u001b[39m.root_directory / \u001b[38;5;28mself\u001b[39m.results_directory\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:759\u001b[39m, in \u001b[36mrmtree\u001b[39m\u001b[34m(path, ignore_errors, onerror, dir_fd)\u001b[39m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:626\u001b[39m, in \u001b[36m_rmtree_unsafe\u001b[39m\u001b[34m(path, onerror)\u001b[39m\n\u001b[32m    624\u001b[39m     os.rmdir(path)\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:624\u001b[39m, in \u001b[36m_rmtree_unsafe\u001b[39m\u001b[34m(path, onerror)\u001b[39m\n\u001b[32m    622\u001b[39m             onerror(os.unlink, fullname, sys.exc_info())\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     os.rmdir(path)\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    626\u001b[39m     onerror(os.rmdir, path, sys.exc_info())\n",
      "\u001b[31mOSError\u001b[39m: [WinError 145] The directory is not empty: 'demo_results'"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Define the root directory for our test results.\n",
    "root_dir = Path(\"demo_results\")\n",
    "\n",
    "# Instantiate the DataHandler.\n",
    "handler = DataHandler(root_directory=root_dir)\n",
    "\n",
    "# Create the folder hierarchy with overwrite enabled.\n",
    "handler.create_folders(overwrite=True)\n",
    "print(\"Folder hierarchy created (overwrite enabled).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a5a34",
   "metadata": {},
   "source": [
    "## Step 2: Register and Add Simulation Data\n",
    "\n",
    "For each iteration, we register three identifiers:\n",
    "\n",
    "- `build_parameters`\n",
    "- `classical_simulation`\n",
    "- `quantum_simulation`\n",
    "\n",
    "Then we add sample data for each identifier using our simulation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Identifiers registered.\n",
      "Iteration 0: Sample data added.\n",
      "Iteration 1: Identifiers registered.\n",
      "Iteration 1: Sample data added.\n",
      "Iteration 2: Identifiers registered.\n",
      "Iteration 2: Sample data added.\n",
      "Iteration 3: Identifiers registered.\n",
      "Iteration 3: Sample data added.\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "for i in range(4):\n",
    "    handler.create_new_iteration()\n",
    "\n",
    "    # Register identifiers for the current iteration.\n",
    "    handler.register_identifier(\"build_parameters\")\n",
    "    handler.register_identifier(\"classical_simulation\")\n",
    "    handler.register_identifier(\"quantum_simulation\")\n",
    "    print(f\"Iteration {i}: Identifiers registered.\")\n",
    "\n",
    "    # Create sample simulation outputs with slight variations.\n",
    "    sample_build = Parameters(\n",
    "        id='build_parameters',\n",
    "        parameters={\"parameter1\": 42 + i, \"parameter2\": f\"value_{i}\", \"type\": \"simulation_result\"}\n",
    "    )\n",
    "    sample_classical = Classical(\n",
    "        id='classical_simulation',\n",
    "        result={\"result\": 3.14 + i}\n",
    "    )\n",
    "    sample_quantum = Quantum(\n",
    "        id='quantum_simulation',\n",
    "        result={\"result\": 2.71 + i}\n",
    "    )\n",
    "\n",
    "    # Add the sample data to the current iteration.\n",
    "    handler.add_data_to_iteration(sample_build.id, sample_build)\n",
    "    handler.add_data_to_iteration(sample_classical.id, sample_classical)\n",
    "    handler.add_data_to_iteration(sample_quantum.id, sample_quantum)\n",
    "    print(f\"Iteration {i}: Sample data added.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0f238",
   "metadata": {},
   "source": [
    "## Step 3: Summarize Iterations\n",
    "\n",
    "We now summarize the stored iterations by reading the metadata from each iteration folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f22709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Summary:\n",
      "{\n",
      "  \"iteration_0\": {\n",
      "    \"iteration_number\": 0,\n",
      "    \"base_path\": \"demo_results\\\\results\\\\iterations\\\\iteration_0\",\n",
      "    \"id_to_description\": {\n",
      "      \"build_parameters\": {\n",
      "        \"path\": \"build_parameters.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.151153\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.153147\"\n",
      "      },\n",
      "      \"classical_simulation\": {\n",
      "        \"path\": \"classical_simulation.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.151153\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.155142\"\n",
      "      },\n",
      "      \"quantum_simulation\": {\n",
      "        \"path\": \"quantum_simulation.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.152150\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.156139\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"iteration_1\": {\n",
      "    \"iteration_number\": 1,\n",
      "    \"base_path\": \"demo_results\\\\results\\\\iterations\\\\iteration_1\",\n",
      "    \"id_to_description\": {\n",
      "      \"build_parameters\": {\n",
      "        \"path\": \"build_parameters.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.157137\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.160128\"\n",
      "      },\n",
      "      \"classical_simulation\": {\n",
      "        \"path\": \"classical_simulation.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.158134\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.161126\"\n",
      "      },\n",
      "      \"quantum_simulation\": {\n",
      "        \"path\": \"quantum_simulation.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.158134\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.162123\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"iteration_2\": {\n",
      "    \"iteration_number\": 2,\n",
      "    \"base_path\": \"demo_results\\\\results\\\\iterations\\\\iteration_2\",\n",
      "    \"id_to_description\": {\n",
      "      \"build_parameters\": {\n",
      "        \"path\": \"build_parameters.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.164118\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.166113\"\n",
      "      },\n",
      "      \"classical_simulation\": {\n",
      "        \"path\": \"classical_simulation.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.164118\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.168108\"\n",
      "      },\n",
      "      \"quantum_simulation\": {\n",
      "        \"path\": \"quantum_simulation.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.165115\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.169105\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"iteration_3\": {\n",
      "    \"iteration_number\": 3,\n",
      "    \"base_path\": \"demo_results\\\\results\\\\iterations\\\\iteration_3\",\n",
      "    \"id_to_description\": {\n",
      "      \"build_parameters\": {\n",
      "        \"path\": \"build_parameters.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.170102\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.173094\"\n",
      "      },\n",
      "      \"classical_simulation\": {\n",
      "        \"path\": \"classical_simulation.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.171101\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.174092\"\n",
      "      },\n",
      "      \"quantum_simulation\": {\n",
      "        \"path\": \"quantum_simulation.json\",\n",
      "        \"start_timestamp\": \"2025-03-30 02:29:31.171101\",\n",
      "        \"status\": \"done\",\n",
      "        \"saved_timestamp\": \"2025-03-30 02:29:31.175089\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "summary = handler.summarize_iterations()\n",
    "print(\"Iteration Summary:\")\n",
    "print(json.dumps(summary, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4e6d4",
   "metadata": {},
   "source": [
    "## Step 4: Aggregate Data and Export as CSV\n",
    "\n",
    "Using an aggregation configuration, we combine data from different simulation outputs. In this example, we set up two aggregations:\n",
    "\n",
    "- **classical:** Combines `build_parameters` and `classical_simulation`\n",
    "- **quantum:** Combines `build_parameters` and `quantum_simulation`\n",
    "\n",
    "After aggregating, the results are saved as CSV files (`classical.csv` and `quantum.csv`) in the aggregations folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Data:\n",
      "{\n",
      "  \"classical\": [\n",
      "    {\n",
      "      \"iteration_number\": 0,\n",
      "      \"parameter1\": 42,\n",
      "      \"parameter2\": \"value_0\",\n",
      "      \"type\": \"simulation_result\",\n",
      "      \"result\": 3.14\n",
      "    },\n",
      "    {\n",
      "      \"iteration_number\": 1,\n",
      "      \"parameter1\": 43,\n",
      "      \"parameter2\": \"value_1\",\n",
      "      \"type\": \"simulation_result\",\n",
      "      \"result\": 4.140000000000001\n",
      "    },\n",
      "    {\n",
      "      \"iteration_number\": 2,\n",
      "      \"parameter1\": 44,\n",
      "      \"parameter2\": \"value_2\",\n",
      "      \"type\": \"simulation_result\",\n",
      "      \"result\": 5.140000000000001\n",
      "    },\n",
      "    {\n",
      "      \"iteration_number\": 3,\n",
      "      \"parameter1\": 45,\n",
      "      \"parameter2\": \"value_3\",\n",
      "      \"type\": \"simulation_result\",\n",
      "      \"result\": 6.140000000000001\n",
      "    }\n",
      "  ],\n",
      "  \"quantum\": [\n",
      "    {\n",
      "      \"iteration_number\": 0,\n",
      "      \"parameter1\": 42,\n",
      "      \"parameter2\": \"value_0\",\n",
      "      \"type\": \"simulation_result\",\n",
      "      \"result\": 2.71\n",
      "    },\n",
      "    {\n",
      "      \"iteration_number\": 1,\n",
      "      \"parameter1\": 43,\n",
      "      \"parameter2\": \"value_1\",\n",
      "      \"type\": \"simulation_result\",\n",
      "      \"result\": 3.71\n",
      "    },\n",
      "    {\n",
      "      \"iteration_number\": 2,\n",
      "      \"parameter1\": 44,\n",
      "      \"parameter2\": \"value_2\",\n",
      "      \"type\": \"simulation_result\",\n",
      "      \"result\": 4.71\n",
      "    },\n",
      "    {\n",
      "      \"iteration_number\": 3,\n",
      "      \"parameter1\": 45,\n",
      "      \"parameter2\": \"value_3\",\n",
      "      \"type\": \"simulation_result\",\n",
      "      \"result\": 5.71\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Aggregated CSV files saved in: demo_results\\results\\aggregations\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Define the aggregation configuration.\n",
    "agg_config = {\n",
    "    \"classical\": (\"build_parameters\", \"classical_simulation\"),\n",
    "    \"quantum\": (\"build_parameters\", \"quantum_simulation\")\n",
    "}\n",
    "\n",
    "# Perform the aggregation using our adapter.\n",
    "aggregated = handler.aggregate_by_config(agg_config, adapter=adapter)\n",
    "print(\"Aggregated Data:\")\n",
    "print(json.dumps(aggregated, indent=2, default=str))\n",
    "\n",
    "# Save aggregated results to CSV files in the aggregations folder.\n",
    "handler.save_aggregation_to_csv(agg_config, adapter=adapter)\n",
    "print(f\"Aggregated CSV files saved in: {handler.aggregations_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d2d24",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we demonstrated a complete workflow using the **DataHandler** module:\n",
    "\n",
    "- **Setup:** Creating the folder structure and iterations.\n",
    "- **Data Management:** Registering simulation outputs and adding sample data.\n",
    "- **Aggregation:** Combining simulation results from multiple iterations and exporting the aggregated data as CSV files.\n",
    "\n",
    "This approach allows you to systematically manage and analyze simulation outputs, seamlessly integrating with the other features of our package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
